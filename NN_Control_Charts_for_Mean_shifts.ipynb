{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/changsksu/IMSE_Data_Science/blob/main/NN_Control_Charts_for_Mean_shifts.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oex88qd38Thn"
      },
      "source": [
        "# NN Control Chart for detecting mean shifts\n",
        "This NN has 10 input nodes, 2 hidden layers, and binary node. The output of 0 means the process is in control and 1 for out of control. A totla of 12000 N(0,1) is used as the in-control training set. The out of control data sets are 4000 N(1,1), 4000 N(2,1), and 4000 N(3,1) respectively. Using 80/20 splits, the testing data set contains IC data: 3000 N(0,1) and 3000 OOC data: 1000 N(mu,1) where mu=1,2,3\n",
        "\n",
        "By Dr. Shing Chang, 2/22/2024 revised 3/25/2024\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate train and testing data sets\n",
        "# in-control data set X N(0,1) 12000\n",
        "# OOC data sets are\n",
        "# small mean shift N(1,1) 4000\n",
        "# medium mean shift N(2,1) 4000\n",
        "# large mean shift N(3,1) 4000\n",
        "# n=10 so the sample size = total obs/n\n",
        "import numpy as np\n",
        "\n",
        "# Set the mean and standard deviation for in\n",
        "mean = 0\n",
        "std_dev = 1\n",
        "\n",
        "# Generate 12,000 normally distributed data points\n",
        "data = np.random.normal(mean, std_dev, 12000)\n",
        "dataICtrain = np.reshape(data, (1200, 10))\n",
        "\n",
        "data = np.random.normal(mean, std_dev, 3000)\n",
        "dataICtest = np.reshape(data, (300, 10))\n",
        "#dataIC\n",
        "# Print the first few data points as an example\n",
        "#print(dataIC[:10])\n",
        "#dataICtrain.shape\n",
        "#dataICtest.shape\n",
        "#\n",
        "#\n",
        "# Generate 400 small shift samples for training 100 for testing\n",
        "mean = 1\n",
        "std_dev = 1\n",
        "data = np.random.normal(mean, std_dev, 4000)\n",
        "dataOC1train = np.reshape(data, (400, 10))\n",
        "data = np.random.normal(mean, std_dev, 1000)\n",
        "dataOC1test = np.reshape(data, (100, 10))\n",
        "\n",
        "# Generate 400 medium shift samples for training 100 for testing (n=10)\n",
        "mean = 2\n",
        "std_dev = 1\n",
        "data = np.random.normal(mean, std_dev, 4000)\n",
        "dataOC2train = np.reshape(data, (400, 10))\n",
        "data = np.random.normal(mean, std_dev, 1000)\n",
        "dataOC2test = np.reshape(data, (100, 10))\n",
        "\n",
        "# Generate 400 large shift samples for training 100 for testing (n=10)\n",
        "mean = 3\n",
        "std_dev = 1\n",
        "data = np.random.normal(mean, std_dev, 4000)\n",
        "dataOC3train = np.reshape(data, (400, 10))\n",
        "data = np.random.normal(mean, std_dev, 1000)\n",
        "dataOC3test = np.reshape(data, (100, 10))\n"
      ],
      "metadata": {
        "id": "4hgNq80jvxIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute x bars and stds for the IC training data\n",
        "# then compute x bar bar and s bar to estimate the overall mean and std of the training process\n",
        "x_bars = np.mean(dataICtrain, axis=1)\n",
        "stds = np.std(dataICtrain, axis=1)\n",
        "x_2bar =np.mean(x_bars)\n",
        "s_bar =np.mean(stds)\n",
        "x_2bar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaASevnJYQ4L",
        "outputId": "902e2ce4-3192-49f1-a83f-499ab8d9ebdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.014589687323112287"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Apply Levine transformation for all datasets\n",
        "# this step is to standardize any dataset (mu, sigma)\n",
        "# all negative data is flipped to the positve side\n",
        "ICtrain = np.abs(dataICtrain - x_2bar) / s_bar\n",
        "ICtest = np.abs(dataICtest - x_2bar) / s_bar\n",
        "OC1train = np.abs(dataOC1train - x_2bar) / s_bar\n",
        "OC1test = np.abs(dataOC1test - x_2bar) / s_bar\n",
        "OC2train = np.abs(dataOC2train - x_2bar) / s_bar\n",
        "OC2test = np.abs(dataOC2test - x_2bar) / s_bar\n",
        "OC3train = np.abs(dataOC3train - x_2bar) / s_bar\n",
        "OC3test = np.abs(dataOC3test - x_2bar) / s_bar\n",
        "# np.mean(OC3train, axis=0)"
      ],
      "metadata": {
        "id": "J8G3vbplb_Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate matrices along rows (vertically) of all training data sets\n",
        "Xtraining = np.concatenate((ICtrain, OC1train, OC2train, OC3train), axis=0)\n",
        "X_train= np.asarray(Xtraining)\n",
        "Xtesting = np.concatenate((ICtest, OC1test, OC2test, OC3test), axis=0)\n",
        "X_test= np.asarray(Xtesting)"
      ],
      "metadata": {
        "id": "0CclDvWDfs4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate target response data\n",
        "# training target Y\n",
        "ICtarget =np.full(1200, 0)\n",
        "OC1target=np.full(400,1)\n",
        "OC2target=np.full(400,1)\n",
        "OC3target=np.full(400,1)\n",
        "Y_train=np.concatenate((ICtarget, OC1target, OC2target, OC3target), axis=0)\n",
        "#\n",
        "# testing target Y\n",
        "ICtarget =np.full(300, 0)\n",
        "OC1target=np.full(100,1)\n",
        "OC2target=np.full(100,1)\n",
        "OC3target=np.full(100,1)\n",
        "Y_test=np.concatenate((ICtarget, OC1target, OC2target, OC3target), axis=0)"
      ],
      "metadata": {
        "id": "yyWQVYnMiWMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtsWoS7hgFBP",
        "outputId": "b004da48-79b3-49ff-98e7-a846cd7bd96f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(600,)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bL4z0BArzqff"
      },
      "source": [
        "# Backward Propagration Training:\n",
        "**Use Keras to define a Neural network that will be trained off of this data. This Neural Network can then be used to predict sample (size n=10) is in control or out of control.**\n",
        "ref. https://keras.io/guides/sequential_model/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoWtmalR80De"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "classifier = Sequential() # Initialising the ANN\n",
        "\n",
        "classifier.add(Dense(units = 10, activation = 'relu', input_dim=10))\n",
        "classifier.add(Dense(units = 20, activation = 'relu'))\n",
        "classifier.add(Dense(units = 20, activation = 'relu'))\n",
        "classifier.add(Dense(units = 1, activation = 'sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ_MStxe9CbN"
      },
      "source": [
        "Specify the optimzer and loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wR2O00E39C7E"
      },
      "source": [
        "classifier.compile(optimizer = 'rmsprop', loss = 'binary_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn9WPqaP9RmN"
      },
      "source": [
        "You now train the neural network using Classifier.fit, passing it the training data -- i.e. for this set of X, this is what the Y should look like. The NN will then spot the patterns in the data, and build a neural network that could replicate that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QlYnFgH9N49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e22a3834-6d34-4837-8558-e340c422e9d2"
      },
      "source": [
        "# try 10 epochs to improve the performance\n",
        "classifier.fit(X_train, Y_train, batch_size = 1, epochs = 10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2400/2400 [==============================] - 9s 3ms/step - loss: 0.4380\n",
            "Epoch 2/10\n",
            "2400/2400 [==============================] - 7s 3ms/step - loss: 0.2874\n",
            "Epoch 3/10\n",
            "2400/2400 [==============================] - 6s 3ms/step - loss: 0.2816\n",
            "Epoch 4/10\n",
            "2400/2400 [==============================] - 7s 3ms/step - loss: 0.2793\n",
            "Epoch 5/10\n",
            "2400/2400 [==============================] - 6s 3ms/step - loss: 0.2833\n",
            "Epoch 6/10\n",
            "2400/2400 [==============================] - 7s 3ms/step - loss: 0.2705\n",
            "Epoch 7/10\n",
            "2400/2400 [==============================] - 6s 3ms/step - loss: 0.2751\n",
            "Epoch 8/10\n",
            "2400/2400 [==============================] - 7s 3ms/step - loss: 0.2755\n",
            "Epoch 9/10\n",
            "2400/2400 [==============================] - 6s 3ms/step - loss: 0.2754\n",
            "Epoch 10/10\n",
            "2400/2400 [==============================] - 7s 3ms/step - loss: 0.2769\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78106693b5e0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After 10 epochs of train, we only achieve about 72% accuracy."
      ],
      "metadata": {
        "id": "xDS_hJg2zjkO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# try 100 epochs to improve the performance\n",
        "# classifier.fit(X_train, Y_train, batch_size = 1, epochs = 100)"
      ],
      "metadata": {
        "id": "C0q-FLE0wigR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your turn: does the increasing training epochs improve the NN performance?**"
      ],
      "metadata": {
        "id": "JpukqhiNxoeQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrnGgtfn9gsE"
      },
      "source": [
        "# Feedforward NN Prediction:\n",
        "To predict new values, the Neural Network uses classifier.predict. The test values for X (which the Neural Network hasn't previously seen) will give back a set of predictions. These predicitons will be probabilities, if thye are greater than .5, the process is deemed out of control. Otherwise, the process is deemed in control."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEaG0Tkx9fUU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "765ba80a-c1f2-43b6-c928-d6f2d00c13ad"
      },
      "source": [
        "Y_pred = classifier.predict(X_test)\n",
        "Y_pred = [ 1 if y>=0.5 else 0 for y in Y_pred ]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQK3Qo9h97OW"
      },
      "source": [
        "Now we can loop through the set of predicitons for the test set (called Y_pred) and the actual values for the test set (celled Y_test), and see how alike they are -- if they are the same, I'll increment 'correct', otherwise I'll incrememnt 'wrong'.\n",
        "\n",
        "You'll see the result is 100% accurate, even though the neural network reported a lower accuracy than that. Why?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he_2VHJ_9yC1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8a54499-a515-4807-cc6e-933b8cbb8d3e"
      },
      "source": [
        "total = 0\n",
        "correct = 0\n",
        "wrong = 0\n",
        "for i in range(len(Y_pred)):\n",
        "  total=total+1\n",
        "  if(Y_test[i] == Y_pred[i]):\n",
        "    correct=correct+1\n",
        "  else:\n",
        "    wrong=wrong+1\n",
        "\n",
        "print(\"Total \" + str(total))\n",
        "print(\"Correct \" + str(correct))\n",
        "print(\"Wrong \" + str(wrong))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 600\n",
            "Correct 539\n",
            "Wrong 61\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct/total"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57Meb048yjX2",
        "outputId": "04234d87-891c-42da-cfc1-38302910ffa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8983333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Your Turn:** what are the other ways to access the false positive and false negative rates? In the SQC literature, false positve is called Type I error where the false negative is called Typle II error (assuming Positive is process is out of control and Negative is process is in control)."
      ],
      "metadata": {
        "id": "oU4I2iF6jvcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# to use the trained NN for monitoring the process\n",
        "# for examle, a sample of 10 with 1.5 sigma shift\n",
        "mean = 0.7\n",
        "std_dev = 1\n",
        "sample1 = np.random.normal(mean, std_dev, 10)\n",
        "transform1 = np.abs(sample1 - x_2bar) / s_bar\n",
        "X_data= np.asmatrix(transform1)\n",
        "outcome1=classifier.predict(X_data)\n",
        "# print(outcome1)\n",
        "print(\"Prediction is \",outcome1)\n",
        "if outcome1>=0.5:\n",
        "    print(\"The process is now out of control\")\n",
        "else:\n",
        "    print(\"The process is in control\")\n",
        "\n"
      ],
      "metadata": {
        "id": "14DQx7VV2Lbj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Your Turn: try various (mean, std_dev) combinations, answer the following questions:\n",
        "1. Does this NN senstive to small process mean shifts?\n",
        "2. Does this NN response to process variance changes?\n",
        "3. How do you improve this NN? (e.g. add sample mean and std as input, more hidden layers, more training data, bigger n, longer training time, etc,)\n",
        "4. Advanced: try CNN and use (time , data, prior trend) as the input where prior trend is the distance away from the target from the previous outcome or CUSUM)"
      ],
      "metadata": {
        "id": "gqtN09q96vOS"
      }
    }
  ]
}